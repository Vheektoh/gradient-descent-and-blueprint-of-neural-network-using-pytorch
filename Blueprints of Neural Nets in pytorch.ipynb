{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f643a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import *\n",
    "from torchsummary import summary\n",
    "from PIL import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db3ff2",
   "metadata": {},
   "source": [
    "### Backpropagation in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169d41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    '''neural network architecture'''\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(). __init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        returnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4137309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add a whole lot of hidden layers in the network above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a31a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate the network\n",
    "model = network(1, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e741b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the weights manually using the diagram from  here\n",
    "model.state_dict()['hidden.weight'][:] = torch.tensor([[1], [-1]])\n",
    "model.state_dict()['hidden.bias'][:] = torch.tensor([1, 2])\n",
    "model.state_dict()['output.weight'][:] = torch.tensor([[1, 2]])\n",
    "model.state_dict()['output.bias'][:] = torch.tensor([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e49aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y data\n",
    "x, y = torch.tensor([1.0]), torch.tensor([3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf25b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59f072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a loss function\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7220eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = criterion(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21232100",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba96e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''inputs the architecture in the neural network'''\n",
    "        super(). __init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=(3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(in_channels=3, out_channels=2, kernel_size=(3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1250, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8215b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e44f196",
   "metadata": {},
   "source": [
    "#### lets define a function to ensure our code usues GPU if available, and defaults to CPU if its not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1717594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks if our computing system has a gpu or not\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bc7f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_devices():\n",
    "    ''' pick GPU if available, else CPU'''\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14475c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_default_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f7af8",
   "metadata": {},
   "source": [
    "#### define a function to move data to chosen device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a15d016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    '''move tensor(s) to chosen device'''\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b73dd",
   "metadata": {},
   "source": [
    "#### define a device or dataloader class to wrap our existing data loaders and move to selected devices(ie puts batches of data to gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5223d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    '''wrap a dataloader to move data to a device'''\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        '''yield a batch of data after moving it to device'''\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "            # yield pauses the execution of a function and return things one by one\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''number of batches'''\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997127a",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34873184",
   "metadata": {},
   "source": [
    "Xt+1= xt- η∆xt\n",
    "- generate predictions\n",
    "- calculate the loss\n",
    "- compute gradients with respect to weights and biases\n",
    "- adjust weights by subtracting a small quantity proportional to the gradient\n",
    "- reset the gradients to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf194653",
   "metadata": {},
   "source": [
    "#### training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6bb0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
    "    # loss batch calculates loss and metric value for a batch of data and optionally performs gradient descent\n",
    "    #generate pred\n",
    "    preds = model(xb)\n",
    "    #calculate loss\n",
    "    loss = loss_func(preds, yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        #compute gradients\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        opt.step()\n",
    "        #reset gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        #compute the metric\n",
    "        metric_result = metric(preds, yb)\n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8333b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, loss_fn, train_dl, valid_dl, metric=None, opt_fn= None):\n",
    "    losses, metrics = [], []\n",
    "    \n",
    "    # instantiate the optimizer\n",
    "    if opt_fn is None:\n",
    "        opt_fn = torch.optim.SGD\n",
    "        opt = opt_fn(model.parameters(), lr = lr)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        #training\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_fn, xb, yb, opt)\n",
    "            \n",
    "        # evaluation\n",
    "        result = evaluate(model, loss_fn, valid_dl, metric)\n",
    "        result = val_loss, total, val_metric\n",
    "        \n",
    "        # record the loss and metric\n",
    "        losses.append(val_loss)\n",
    "        metrics.append(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2d6655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.sum(preds == labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb126551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
